if (any(is.na(dataset[[colname]]))) next
# Aplicar la prueba chi-cuadrado
tab <- table(dataset[[colname]])
if (length(tab) > 1) {  # Asegurarse de que hay más de una categoría
chi_squared_test <- chisq.test(tab)
if (chi_squared_test$p.value < 0.05) {
dataset <- count_encode(colname, dataset)
} else {
dataset <- one_hot_encoder(colname, dataset)
}
}
}
return(dataset)
}
# Handling missing values
na_value <- function(dataset) {
na_columns <- names(dataset)[sapply(dataset, function(x){
any(is.na(x)) || any(is.nan(x))
})]
if (length(na_columns) > 0) {
dataset[na_columns] <- lapply(dataset[na_columns], function(column) {
column <- as.numeric(column)
mean_value <- mean(column, na.rm = TRUE)
ifelse(is.na(column), mean_value, column)
})
}
return(dataset)
}
# Correlation analysis
correlation <- function(df, threshold = 0.9) {
# Calcular la matriz de correlación
corr_matrix <- cor(df)
# Encontrar índices de correlaciones altas
high_corr_indices <- which(abs(corr_matrix) > threshold, arr.ind = TRUE)
# Crear un vector para almacenar los nombres de las variables a eliminar
var_to_remove <- c()
# Iterar sobre los pares de índices de correlaciones altas
for (index in 1:nrow(high_corr_indices)) {
i <- high_corr_indices[index, 1]
j <- high_corr_indices[index, 2]
# Asegurarse de que no estamos en la diagonal y que la variable no se ha añadido todavía
if (i != j) {
var_i <- colnames(df)[i]
var_j <- colnames(df)[j]
# Añadir la variable al vector de eliminación si no está ya incluida
if (!(var_i %in% var_to_remove) && !(var_j %in% var_to_remove)) {
var_to_remove <- c(var_to_remove, var_i)
}
}
}
# Eliminar las variables altamente correlacionadas
df <- df[, !(colnames(df) %in% var_to_remove)]
return(df)
}
data <- open_csv(path_file = "C:/Users/mario/Documents/R/stroke.csv")
data$id <- NULL
data <- true_na(data)
categorical <- colnames(data)[sapply(data, function(x) !is.numeric(x))]
categorical <- categorical[-which(categorical == "bmi")]
data <- encode(dataset = data, categorical_columns = categorical)
data <- na_value(data)
library(ggplot2)
# Calcular la matriz de correlaciones
corr_matrix <- cor(dataframe)
head(data)
corr_matrix <- cor(dataframe)
# Calcular la matriz de correlaciones
corr_matrix <- cor(dataframe, na.rm = TRUE)
library(ggplot2)
# Calcular la matriz de correlaciones
corr_matrix <- cor(data)
# Convertir la matriz de correlación a un formato largo
corr_melted <- reshape2::melt(as.data.frame(corr_matrix))
# Crear el gráfico de calor
ggplot(data = corr_melted, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = '', y = '', title = 'Heatmap of Correlation Matrix')
open_csv <- function(path_file) {
dataframe <- read.csv(path_file)
return(dataframe)
}
# Special scenario: NA values are encoded as 'N/A'
true_na <- function(dataset) {
# First we exchange N/A for NA
dataframe_NA <- data.frame(lapply(dataset, function(x) {
if (is.character(x) || is.factor(x)) {
x[x == 'N/A'] <- NA
return(x)
} else {
return(x)
}
}))
return(dataframe_NA)
}
# Categorical variable encoding
count_encode <- function(colname, dataset) {
frequencies <- table(dataset[[colname]]) / nrow(dataset)
dataset[[paste(colname, "count_encoded", sep = "_")]] <- sapply(dataset[[colname]], function(elem) {
frequencies[as.character(elem)]
})
dataset[[colname]] <- NULL
return(dataset)
}
one_hot_encoder <- function(colname, dataset) {
# Crear un model.matrix para la columna especificada
formula <- as.formula(paste("~", colname, "- 1"))
encoded_col <- model.matrix(formula, data=dataset)
colnames(encoded_col) <- paste(colname, gsub(" ", ".", colnames(encoded_col)), sep = "_")
# Combinar el dataset original con las nuevas columnas codificadas
final_data <- cbind(dataset, encoded_col)
# Eliminar la columna original que se codificó
final_data[[colname]] <- NULL
return(final_data)
}
encode <- function(dataset, categorical_columns) {
for (colname in categorical_columns) {
# Asegurarse de que no hay valores NA antes de realizar la prueba chi-cuadrado
if (any(is.na(dataset[[colname]]))) next
# Aplicar la prueba chi-cuadrado
tab <- table(dataset[[colname]])
if (length(tab) > 1) {  # Asegurarse de que hay más de una categoría
chi_squared_test <- chisq.test(tab)
if (chi_squared_test$p.value < 0.05) {
dataset <- count_encode(colname, dataset)
} else {
dataset <- one_hot_encoder(colname, dataset)
}
}
}
return(dataset)
}
# Handling missing values
na_value <- function(dataset) {
na_columns <- names(dataset)[sapply(dataset, function(x){
any(is.na(x)) || any(is.nan(x))
})]
if (length(na_columns) > 0) {
dataset[na_columns] <- lapply(dataset[na_columns], function(column) {
column <- as.numeric(column)
mean_value <- mean(column, na.rm = TRUE)
ifelse(is.na(column), mean_value, column)
})
}
return(dataset)
}
# Correlation analysis
correlation <- function(df, threshold = 0.9) {
# Calcular la matriz de correlación
corr_matrix <- cor(df)
# Encontrar índices de correlaciones altas
high_corr_indices <- which(abs(corr_matrix) > threshold, arr.ind = TRUE)
# Crear un vector para almacenar los nombres de las variables a eliminar
var_to_remove <- c()
# Iterar sobre los pares de índices de correlaciones altas
for (index in 1:nrow(high_corr_indices)) {
i <- high_corr_indices[index, 1]
j <- high_corr_indices[index, 2]
# Asegurarse de que no estamos en la diagonal y que la variable no se ha añadido todavía
if (i != j) {
var_i <- colnames(df)[i]
var_j <- colnames(df)[j]
# Añadir la variable al vector de eliminación si no está ya incluida
if (!(var_i %in% var_to_remove) && !(var_j %in% var_to_remove)) {
var_to_remove <- c(var_to_remove, var_i)
}
}
}
# Eliminar las variables altamente correlacionadas
df <- df[, !(colnames(df) %in% var_to_remove)]
return(df)
}
data <- open_csv(path_file = "C:/Users/mario/Documents/R/stroke.csv")
data$id <- NULL
data <- true_na(data)
categorical <- colnames(data)[sapply(data, function(x) !is.numeric(x))]
categorical <- categorical[-which(categorical == "bmi")]
data <- encode(dataset = data, categorical_columns = categorical)
data <- na_value(data)
library(ggplot2)
# Calcular la matriz de correlaciones
corr_matrix <- cor(data)
# Convertir la matriz de correlación a un formato largo
corr_melted <- reshape2::melt(as.data.frame(corr_matrix))
# Crear el gráfico de calor
ggplot(data = corr_melted, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = '', y = '', title = 'Heatmap of Correlation Matrix')
# Asegúrate de que 'reshape2' esté instalado y cargado
library(reshape2)
# Asegurándose de que la matriz de correlaciones tiene nombres de fila/columna adecuados
rownames(corr_matrix) <- colnames(data)
colnames(corr_matrix) <- colnames(data)
# Convertir la matriz de correlación a un formato largo
corr_melted <- melt(corr_matrix)
# Crear el gráfico de calor con ggplot2
library(ggplot2)
ggplot(data = corr_melted, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1, 1), space = "Lab",
name = "Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = '', y = '', title = 'Heatmap of Correlation Matrix')
data <- correlation(df = data, threshold = 0.9)
head(data)
calc_momento <- function(orden, datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^orden * datos$fi[i]
})
return(sum(resultado))
}
calc_sd <- function(datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^2 * datos$fi[i]
})
return(sqrt(sum(resultado)))
}
marcas_clase <- c(18,21,23,25,27,29,31,34,38)
ni <- c(30,40,35,25,15,15,20,10,10)
datos = data.frame(
xi = marcas_clase,
ni = ni,
fi = calc_fi(marcas_clase, ni)
)
# Funciones
calc_ni <- function(datos_in, xi_in) {
ni <- sapply(xi_in, function(valor) {
sum(datos_in == valor)
})
return(ni)
}
calc_fi <- function(datos_in, ni_in) {
total <- sum(ni_in)
fi <- sapply(ni_in, function(valor) {
valor/total
})
return(fi)
}
calc_acumulada <- function(frecuencia_in) {
frec_acumulada <- c(frecuencia_in[1])
for (i in 2:length(frecuencia_in)) {
frec_acumulada <- c(frec_acumulada,
frec_acumulada[i-1] + frecuencia_in[i])
}
return(frec_acumulada)
}
# Main
datos <- c(1,3,2,2,3,1,1,2,2,1,
1,4,3,1,3,2,3,2,2,2,
1,2,5,1,3,1,2,1,3,1,
4,1,1,3,4,2,2,1,1,4)
xi <- sort(unique(datos))
ni <- calc_ni(datos, xi)
fi <- calc_fi(datos, ni)
ni_acumulada <- calc_acumulada(ni)
fi_acumulada <- calc_acumulada(fi)
resultado <- data.frame(
xi = xi,
ni = ni,
fi = fi,
Ni = ni_acumulada,
Fi = fi_acumulada
)
print(resultado)
datos = data.frame(
xi = marcas_clase,
ni = ni,
fi = calc_fi(marcas_clase, ni)
)
calc_momento <- function(orden, datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^orden * datos$fi[i]
})
return(sum(resultado))
}
calc_sd <- function(datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^2 * datos$fi[i]
})
return(sqrt(sum(resultado)))
}
marcas_clase <- c(18,21,23,25,27,29,31,34,38)
ni <- c(30,40,35,25,15,15,20,10,10)
datos = data.frame(
xi = marcas_clase,
ni = ni,
fi = calc_fi(marcas_clase, ni)
)
datos
asimetria_fisher <- calc_momento(3, datos) / (calc_sd(datos))^3
asimetria_fisher <- calc_momento(3, datos) / (calc_sd(datos))^3
asimetria_fisher
barp <- barplot(datos$ni,
names.arg=datos$xi,
col="blue",
main="Frecuencias Absolutas",
xlab="Categorías", ylab="Frecuencia Relativa", ylim=c(0, 1))
barp <- barplot(datos$ni,
names.arg=datos$xi,
col="blue",
main="Frecuencias Absolutas",
xlab="Categorías", ylab="Frecuencia Relativa")
calc_momento <- function(orden, datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^orden * datos$fi[i]
})
return(sum(resultado))
}
calc_sd <- function(datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^2 * datos$fi[i]
})
return(sqrt(sum(resultado)))
}
marcas_clase <- c(18,21,23,25,27,29,31,34,38)
ni <- c(30,40,35,25,15,15,20,10,10)
datos = data.frame(
xi = marcas_clase,
ni = ni,
fi = calc_fi(marcas_clase, ni)
)
datos
asimetria_fisher <- calc_momento(3, datos) / (calc_sd(datos))^3
barp <- barplot(datos$ni,
names.arg=datos$xi,
col="blue",
main="Frecuencias Absolutas",
xlab="Categorías", ylab="Frecuencia Relativa")
barp <- barplot(datos$ni,
names.arg=datos$xi,
col="blue",
main="Frecuencias Absolutas",
xlab="Categorías", ylab="Frecuencia Absolutas")
calc_momento <- function(orden, datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^orden * datos$fi[i]
})
return(sum(resultado))
}
calc_sd <- function(datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^2 * datos$fi[i]
})
return(sqrt(sum(resultado)))
}
marcas_clase <- c(18,21,23,25,27,29,31,34,38)
ni <- c(30,40,35,25,15,15,20,10,10)
datos = data.frame(
xi = marcas_clase,
ni = ni,
fi = calc_fi(marcas_clase, ni)
)
datos
asimetria_fisher <- calc_momento(3, datos) / (calc_sd(datos))^3
barp <- barplot(datos$ni,
names.arg=datos$xi,
col="blue",
main="Frecuencias Absolutas",
xlab="Categorías", ylab="Frecuencia Absolutas")
print(paste("Coeficiente de asimetría de Fisher: " + asimetria_fisher + " >0 Por lo que asimetría positiva o a la derecha"))
print(paste("Coeficiente de asimetría de Fisher: " + asimetria_fisher + " >0 Por lo que asimetría positiva o a la derecha"))
print(paste("Coeficiente de asimetría de Fisher: ", asimetria_fisher, " >0 Por lo que asimetría positiva o a la derecha"))
calc_momento <- function(orden, datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^orden * datos$fi[i]
})
return(sum(resultado))
}
calc_sd <- function(datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^2 * datos$fi[i]
})
return(sqrt(sum(resultado)))
}
marcas_clase <- c(18,21,23,25,27,29,31,34,38)
ni <- c(30,40,35,25,15,15,20,10,10)
datos = data.frame(
xi = marcas_clase,
ni = ni,
fi = calc_fi(marcas_clase, ni)
)
datos
asimetria_fisher <- calc_momento(3, datos) / (calc_sd(datos))^3
barp <- barplot(datos$ni,
names.arg=datos$xi,
col="blue",
main="Frecuencias Absolutas",
xlab="Categorías", ylab="Frecuencia Absolutas")
print(paste("Coeficiente de asimetría de Fisher: ", asimetria_fisher, " >0 Por lo que asimetría positiva o a la derecha"))
# Funciones
calc_ni <- function(datos_in, xi_in) {
ni <- sapply(xi_in, function(valor) {
sum(datos_in == valor)
})
return(ni)
}
calc_fi <- function(datos_in, ni_in) {
total <- sum(ni_in)
fi <- sapply(ni_in, function(valor) {
valor/total
})
return(fi)
}
calc_acumulada <- function(frecuencia_in) {
frec_acumulada <- c(frecuencia_in[1])
for (i in 2:length(frecuencia_in)) {
frec_acumulada <- c(frec_acumulada,
frec_acumulada[i-1] + frecuencia_in[i])
}
return(frec_acumulada)
}
# Main
datos <- c(1,3,2,2,3,1,1,2,2,1,
1,4,3,1,3,2,3,2,2,2,
1,2,5,1,3,1,2,1,3,1,
4,1,1,3,4,2,2,1,1,4)
xi <- sort(unique(datos))
ni <- calc_ni(datos, xi)
fi <- calc_fi(datos, ni)
ni_acumulada <- calc_acumulada(ni)
fi_acumulada <- calc_acumulada(fi)
resultado <- data.frame(
xi = xi,
ni = ni,
fi = fi,
Ni = ni_acumulada,
Fi = fi_acumulada
)
print(resultado)
barp <- barplot(resultado$fi,
names.arg=resultado$xi,
col="blue",
main="Frecuencias Relativas",
xlab="Categorías", ylab="Frecuencia Relativa", ylim=c(0, 1))
lines(barp,
resultado$Fi,
type='o',
col="red",
lwd=2) # 'lwd' es el ancho de la línea
legend("topleft",                      # Ubicación de la leyenda
legend=c("Frecuencias Relativas", "Fi (Acumulada)"), # Textos de la leyenda
fill=c("blue", "red"))             # Colores correspondientes
# Funciones
calc_moda <- function(tabla_frecuencias) {
if (any(names(tabla_frecuencias) == "fi")) {
max_freq <- max(tabla_frecuencias$fi)
modas <- tabla_frecuencias$xi[tabla_frecuencias$fi == max_freq]
} else {
print("El dataset debe incluir la columna de frecuencias relativas")
}
return(modas)
}
# Main
media <- mean(datos)
mediana <- median(datos)
moda <- calc_moda(resultado)
print(paste("Media: ", media, "Mediana: ", mediana, "Moda: ", paste(moda, collapse = ", ")))
calc_momento <- function(orden, datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^orden * datos$fi[i]
})
return(sum(resultado))
}
calc_sd <- function(datos) {
media <- sum(datos$xi * datos$fi)
resultado <- sapply(1:length(datos$xi), function(i) {
(datos$xi[i] - media)^2 * datos$fi[i]
})
return(sqrt(sum(resultado)))
}
marcas_clase <- c(18,21,23,25,27,29,31,34,38)
ni <- c(30,40,35,25,15,15,20,10,10)
datos = data.frame(
xi = marcas_clase,
ni = ni,
fi = calc_fi(marcas_clase, ni)
)
datos
asimetria_fisher <- calc_momento(3, datos) / (calc_sd(datos))^3
barp <- barplot(datos$ni,
names.arg=datos$xi,
col="blue",
main="Frecuencias Absolutas",
xlab="Categorías", ylab="Frecuencia Absolutas")
print(paste("Coeficiente de asimetría de Fisher: ", asimetria_fisher, "> 0 Por lo que asimetría positiva o a la derecha"))
qq
unlink("C:/Users/mario/OneDrive/Académico/Universidad/UMA/AA Ingeniería de la Salud/Tercer Año/Estadística/Programación en R/ejercicios-sixto_cache", recursive = TRUE)
setwd("C:/Users/mario/OneDrive/Académico/Universidad/UMA/AA Ingeniería de la Salud/Tercer Año/Estadística/Programación en R/Estadistica-basica-con-R")
install.packages("xfun")
install.packages("Rtools")
